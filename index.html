<!DOCTYPE HTML>
<!--
  Escape Velocity by HTML5 UP
  html5up.net | @ajlkn
  Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
  <head>
    <title>Object Recognition. A Data Science Project by Jacques Oelofse</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
    <link rel="stylesheet" href="assets/css/main.css" />
    <!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
    <link href="dist/css//lightbox.css" rel="stylesheet">
  </head>
  <body class="homepage">
    <div id="page-wrapper">

      <!-- Header -->
      <div id="header-wrapper" class="wrapper">
        <div id="header">

          <!-- Logo -->
          <div id="logo">
            <h1><a href="index.html">Object Recognition</a></h1>
            <p>A Data Science project <br>By Jacques Oelofse</p>
          </div>
        </div>
      </div>

      <!-- Intro -->
      <div id="intro-wrapper" class="wrapper style1">
        <div class="title">The Introduction</div>
        <section id="intro" class="container">
          <p class="style1">So in case you were wondering what this is all about ...</p>
          <p class="style2">
          Machine Learning &amp; Computer Vision <br class="mobile-hide" />
          in Manufacturing<br class="mobile-hide" />
          <p class="style3">Computer vision and MES (Manufacturing Execution Systems have been around for some time. <strong>They are very costly to 
            install and maintain, and complicated to configure.</strong> For this reason, most factories in China still use<strong> spreadsheets.</strong></p>
          <br>
          <p class="style3">In this project I want to create <strong>cost effective and very easy to deploy and maintain</strong> software to track production line metrics
          for the vast amount of supiers and sub suppliers needed to successfully build a product. The aim is not be 100% accurate but rather to give people complete  
          visibility into their manufacturing in China. <strong>Think Fitbit for manufacturing.</strong>
          </p>
          <br> 
          <p class="style3">This project will demonstrate how we use data from images to build a model and predict products on a production line.</p>
          <br>
          <p class="style1">The goal is to have the ability to quickly train a new product and predict it with at least a 90% accuracy.</p>
          <br> INSERT VIDEO HERE!
          <!--<ul class="actions">-->
          <!--<li><a href="#" class="button style3 big">Proceed</a></li>-->
          <!--</ul>-->
        </section>
      </div>

      <!-- Data -->
      <div class="wrapper style2">
        <div class="title">The Data</div>
        <div id="main" class="container">

          <!-- Features -->
          <section id="features">
            <header class="style1">
              <h2>Data consists of images taken overhead from a Logitech C525 webcam</h2>
            </header>
            <!--Image -->
            <a href="#" class="image featured">
              <img src="images/collage_prod2.jpg" alt="" />
            </a>

            <header style="margin-bottom:1em;padding-bottom:0.5em;" class="style1">
              <p style="margin:0em; margin-bottom:2em; line-height:0em;">Important considerations when working with images</p>
            </header>
            <h3>Computers dont see images like humans do</h3>
            <p>Computers see images with number representations for each pixel (see figl below) If an image has 6x9 pixels (height x width), the computer would see 6x9 = 54 
            number values.</p>
            <h3>Color</h3>
            <p>When an image has color, you are adding 3 additional dimentions. The image will now have three number values for
            each pixel. One for red, one for green and one for blue (RGB). The combination of these values make up your color spectrum (fig2).
            The computer will see the colored image as (6x9)x3 = 162.
            <header style="margin-bottom:1em;padding-bottom:0.5em; margin-top:0; padding-top:0;" class="style1">
              <table>
                <tr>
                  <td>
                    <img src="images/image_array.png" alt="" />
                  </td>
                  <td>
                    <img src="images/rgb.gif" alt="" />
                  </td>
                  <tr>
                    <td>fig1</td>
                    <td>fig2</td>
                  </tr>
              </table>
            </header>
            <h3>Size</h3>
            <p>Important when deciding what level of detail you want to extract from the image, and is usually one of the 
            biggest contributing factors on performance.</p>
            <h3>Angle, Rotation, Scale</h3>
            Because computers do not interpret images the same way humans do, they do not automatically understand differences 
            in angle scale and rotation e.g., if you were to look at an person from the front or side, you inherantly know its the same person, 
            a computer however will not know the difference unless you specifically program it to.
            <h3>Image Segmentation</h3>
            <h3>Image Dataset</h3>
          </section>
        </div>
      </div>

      <!-- Features -->
      <div class="wrapper style3">
        <div class="title">Image Descriptors</div>
        <div style="padding:0 6em 0 6em;" id="highlights" class="container">
          <header class="style1">
            <h2>Given two images, how can we determine their similarity?</h2>
            <p>Given two images, how can we determine their similarity? We can measure the pixel to pixel similarity by measuring their Euclidean distance, but that measure is very sensitive to noise, rotation, translation and illumination changes. In most applications we would like to be robust to such change.</p>
            <p>To allow for rotation and scale invariance, we have selected the SURF algoritm to extract the image features. I will give a brief overview of how HOG algorithms works</p>
          </header>
          <h3>1. Detect keypoints</h3>
          <p>
          The most distinctive points on an image are its corners and edges. Think of a jigsaw puzzle. It is easier to together pieces with edges of buildings than pieces of blank sky.
          Simalarly the algoritm will use edges an corners as interest points.The Laplacian of the Gaussian is used to detect keypoints. Log acts as a blob detector which 
          can detect blobs in various sizes. An orientation is calculated for each key point. Any further calculations are done relative to this orientation. This effectively cancels out the effect of orientation, making it rotation invariant.
          </p>
          <div style="margin:0em;background-color:white;height:200px">
            <img style="float:left;margin-bottom:20px;margin-right:20px;" height="200" width="550" src="images/16x16.jpg" alt="" />
            <h3>2. Build image descriptors around keypoints</h3>
            <p style="margin-right:100px;">
            A 16x16 pixel area or descriptor is built around the center of each interest point.
            </p>
          </div>

          <div style="clear:both;height:250px;background-color:white;">
            <img style="float:left;margin-bottom:20px;margin-right:20px;" height="250" width="550" src="images/gradients.jpg" alt="" />
            <h3>3. Compute gradients</h3>
            <p style="margin-right:20px">The 16x16 pixels are divided into 4x4 squares and the pixel gradients are calculted. The shows the direction in which the pixels are getting darker.
            </p>
          </div>

          <div style="clear:both;height:250px;background-color:white;">
            <img style="float:left;margin-bottom:20px;margin-right:20px;" height="250" width="550" src="images/hog.jpg" alt="" />
            <h3>4. Compute gradient direction histogram</h3>
            <p style="margin-right:20px">
            For each square, compute gradient direction histogram over the 8 directions
            </p>
            <br>
          </div>
          <div style="clear:both;height:100px;background-color:white;">
            <img style="float:left;margin-bottom:20px;margin-right:20px;" height="100" width="550" src="images/128hist.jpg" alt="" />
            <h3>5. Concatenate histograms</h3>
            <p>
            Concatenate the histograms to obtain a 128 (16*8) dimensional feature vector
            </p>
          </div>
          <div style="clear:both;">
            <h3>We now have 128 byte vectors for each keypoints found on our image. To compare feature vectors for similarity you can calculate the Euclidean distance.
              For our classification problem to detect which product is in an image, we will use a visual bag of words.<h3>
          </div>
        </div>
      </div>

      <!-- BOW -->
      <div id="footer-wrapper" class="wrapper">
        <div class="title">Visual Bag Of Words</div>
        <div style="padding:0 6em 0 6em;" id="footer" class="container">
          <header class="style1">
            <!--<h2>Ipsum sapien elementum portitor?</h2>-->
            <p>Bag of words models are a popular technique for image classification inspired by models used in natural language processing. The model ignores or downplays word arrangement (spatial information in the image) and classifies based on a histogram of the frequency of visual words.</p>
          </header>
          <hr />
          <h3>Why have a vocabulary?</h3>
          <p>
          Images dont have words so we will have to create our own vocabulary. Once we have a vocabulary that describes all the interest points in our images, we can 
          then check how many words each image contains. We can then use the amount of times the words appear to classify the image. If an image had the words eyes, mouth and nose for example, we would classify it as face.
          </p>

          <h3>1. Build a vocabulary of words</h3>
          <p>
          By using the knn clustering algorithm on the feature descriptors of all of our images. We can group the descriptors into k 
          mutually exclusive clusters. Each cluster center represents a feature, or visual word. All the words will make up the vocabulary.
          <center><img style="" src="images/visualwordsoverview.png" alt="" /></center>
          </p>

          <h3>2. Create Feature Histogram for Images</h3>
          <p>To create the frequence histogram for each image that, we get the descriptors for all each of our images
          and get get their nearest neighbors to the vocbulary we had created. The amount of times the words match the vocabulary will make up our frequency histogram.</p>
          <center><img style="" src="images/bagoffeatures.png" alt="" /></center>

          <h3>Example</h3>
          <p>
          Images show a basic example of visual BOW. The first image shows our image set. The second image shows what the bag of words might look like 
          after we have clustered the descriptors. The final image shows what a frequency histogram representation of each image might look like.
          <center><img style="" src="images/bow1.png" alt="" /></center>
          <center><img style="" src="images/bow2.png" alt="" /></center>
          <center><img style="" src="images/bow3.png" alt="" /></center>
          </p>
        </div>
      </div>
    </div>


    <!-- Classififaction -->
    <div class="wrapper style2">
      <div class="title">Classification</div>
      <div id="main" class="container">
        <!-- Features -->
        <section id="features">
          <header class="style1">
            <h2>Using the feature histograms from our BOW's we will now train a few models and evaluate their performance.</h2>
            <p>Add thumbnails here?!!?</p>
          </header>
          <h3>Train and Test Data</h3>
          <p>
          We have 10 different classes in total to classify. You can see them TODO!!! here.
          For each class we have created roughly 100 images with a total of 1056 images.
          When evaluating the model<strong> we use a test train split of 20% and 80% respectively.</strong>
          </p>
          <h3>Peformance with little data</h3>
          <p>SVM and Logistic Regression performed particularly well with very little training data. With a model trained with only two images per class, they 
					get roughly 60% preciasion and recall however the results can vary significantly when re-training which can be espected because of the small training set.</p>
						<table class="default">
							<thead>
								<tr>
									<th>Model</th>
									<th>Precision</th>
									<th>Recall</th>
									<th>F1-score</th>
									<th>Support</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>Support Vector</td>
									<td>0.70</td>
									<td>0.70</td>
									<td>0.71</td>
									<td>10</td>
								</tr>
								<tr>
									<td>Logistic</td>
									<td>0.63</td>
									<td>0.70</td>
									<td>0.63</td>
									<td>10</td>
								</tr>
								<tr>
									<td>Support Vector RBF</td>
									<td>0.53</td>
									<td>0.50</td>
									<td>0.49</td>
									<td>10</td>
								</tr>
								<tr>
									<td>Random Forest</td>
									<td>0.40</td>
									<td>0.40</td>
									<td>0.37</td>
									<td>10</td>
								</tr>
								<tr>
									<td>Decision Tree</td>
									<td>0.30</td>
									<td>0.30</td>
									<td>0.27</td>
									<td>10</td>
								</tr>
								<tr>
									<td>K Nearest Neigbors</td>
									<td>0.27</td>
									<td>0.40</td>
									<td>0.31</td>
									<td>10</td>
								</tr>
							</tbody>
						</table>

          <h3>Classify 5 Classes</h3>
					<p>With 5 classes with a hundered training images each, the model performs very well at around 97% precision and recall.</p>
						<table class="default">
							<thead>
								<tr>
									<th>Model</th>
									<th>Precision</th>
									<th>Recall</th>
									<th>F1-score</th>
									<th>Support</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>Support Vector</td>
									<td>0.97</td>
									<td>0.97</td>
									<td>0.97</td>
									<td>103</td>
								</tr>
								<tr>
									<td>Logistic</td>
									<td>0.97</td>
									<td>0.97</td>
									<td>0.97</td>
									<td>103</td>
								</tr>
								<tr>
									<td>Support Vector RBF</td>
									<td>0.95</td>
									<td>0.94</td>
									<td>0.94</td>
									<td>103</td>
								</tr>
								<tr>
									<td>Random Forest</td>
									<td>0.91</td>
									<td>0.90</td>
									<td>0.90</td>
									<td>103</td>
								</tr>
								<tr>
									<td>Decision Tree</td>
									<td>0.86</td>
									<td>0.83</td>
									<td>0.84</td>
									<td>103</td>
								</tr>
								<tr>
									<td>K Nearest Neigbors</td>
									<td>0.85</td>
									<td>0.70</td>
									<td>0.70</td>
									<td>103</td>
								</tr>
							</tbody>
						</table>

          <h3>Classify 10 Clasess</h3>
          <p>Classifying 10 different product double what we did last, the result is excelent with an increase in performance. The 10 class image set was taken at a higher reslotuion, however the images have been resized to the same size as the 5 class image set.
          The diffent images may account for the slight increase in performance.</p>
          <table class="default">
							<thead>
								<tr>
									<th>Model</th>
									<th>Precision</th>
									<th>Recall</th>
									<th>F1-score</th>
									<th>Support</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>Support Vector</td>
									<td>0.99</td>
									<td>0.99</td>
									<td>0.99</td>
									<td>212</td>
								</tr>
								<tr>
									<td>Logistic</td>
									<td>0.94</td>
									<td>0.92</td>
									<td>0.92</td>
									<td>212</td>
								</tr>
								<tr>
									<td>Support Vector RBF</td>
									<td>0.99</td>
									<td>0.99</td>
									<td>0.99</td>
									<td>212</td>
								</tr>
								<tr>
									<td>Random Forest</td>
									<td>0.96</td>
									<td>0.96</td>
									<td>0.96</td>
									<td>212</td>
								</tr>
								<tr>
									<td>Decision Tree</td>
									<td>0.85</td>
									<td>0.84</td>
									<td>0.84</td>
									<td>212</td>
								</tr>
								<tr>
									<td>K Nearest Neigbors</td>
									<td>0.97</td>
									<td>0.96</td>
									<td>0.96</td>
									<td>212</td>
								</tr>
							</tbody>
						</table>

          <h3>Image Size on Performance</h3>
          <p>Here we wanted to look at what impact image size would have on the models performance. With every increase of about 100px width (width and hight changed proportionally), the performance went up roughly 2%
          </br> 
          click to zoom </br>
					<a href="images/image_scores.png" data-lightbox="image-1" data-title="Image Size Scores"><img width="100" style="" src="images/image_scores.png" alt="" /></a>
          </p>
          <h3>BOW Size / Feature importance</h3>
          <p>
          BOW size will impact how many words KNN clusters which will be the size of you feature dimention. The more words you have, the more detail can be extracted from each image.
          To decide the ideal size for the BOW we looked at feature importances from the Random Forest model. This is show as "gini importance" or "mean decrease impurity" and is defined as the total decrease in node impurity as percentage ranked by importance

           </br> 
          click to zoom </br>
					<a href="images/bow_scores.png" data-lightbox="image-1" data-title="BOW Scores"><img width="100" style="" src="images/bow_scores.png" alt="" /></a>
          </p>
          <center><img style="" src="images/feature_importance.png" alt="" /></center>

          <h3>Summary</h3>
					<a href="images/collage_prod2.jpg" data-lightbox="image-1" data-title="My caption">Image #1</a>
        </section>
      </div>
    </div>

    <!-- Features -->
    <div class="wrapper style3">
      <div class="title">The Features</div>
      <div style="padding:0 6em 0 6em;" id="highlights" class="container">
        <header class="style1">
          <h2>A feature is a distinctive attribute or aspect of something</h2>
          <p>Given two images, how can we determine their similarity? We can measure the pixel to pixel similarity by measuring their Euclidean distance, but that measure is very sensitive to noise, rotation, translation and illumination changes. In most applications we would like to be robust to such change.</p>
          <p>To allow for rotation and scale invariance, we have selected the SURF algoritm to extract the image features. I will give a brief overview of how HOG algorithms works</p>
        </header>
        <h3>1. Detect keypoints</h3>
        <p>
        The most distinctive points on an image are its corners and edges. Think of a jigsaw puzzle. It is easier to together pieces with edges of buildings than pieces of blank sky.
        Simalarly the algoritm will use edges an corners as interest points.The Laplacian of the Gaussian is used to detect keypoints. Log acts as a blob detector which 
        can detect blobs in various sizes. An orientation is calculated for each key point. Any further calculations are done relative to this orientation. This effectively cancels out the effect of orientation, making it rotation invariant.
        </p>
        <div style="margin:0em;background-color:white;height:200px">
          <img style="float:left;margin-bottom:20px;margin-right:20px;" height="200" width="550" src="images/16x16.jpg" alt="" />
          <h3>2. Build image descriptors around keypoints</h3>
          <p style="margin-right:100px;">
          A 16x16 pixel area or descriptor is built around the center of each interest point.
          </p>
        </div>
      </div>
    </div>

    <!-- Footer -->
    <div id="footer-wrapper" class="wrapper">
      <div class="title">The Rest Of It</div>
      <div id="footer" class="container">
        <header class="style1">
          <h2>Ipsum sapien elementum portitor?</h2>
          <p>
          Sed turpis tortor, tincidunt sed ornare in metus porttitor mollis nunc in aliquet.<br />
          Nam pharetra laoreet imperdiet volutpat etiam consequat feugiat.
          </p>
        </header>
        <hr />
        <div class="row 150%">
          <div class="6u 12u(mobile)">

            <!-- Contact Form -->
            <section>
              <form method="post" action="#">
                <div class="row 50%">
                  <div class="6u 12u(mobile)">
                    <input type="text" name="name" id="contact-name" placeholder="Name" />
                  </div>
                  <div class="6u 12u(mobile)">
                    <input type="text" name="email" id="contact-email" placeholder="Email" />
                  </div>
                </div>
                <div class="row 50%">
                  <div class="12u">
                    <textarea name="message" id="contact-message" placeholder="Message" rows="4"></textarea>
                  </div>
                </div>
                <div class="row">
                  <div class="12u">
                    <ul class="actions">
                      <li><input type="submit" class="style1" value="Send" /></li>
                      <li><input type="reset" class="style2" value="Reset" /></li>
                    </ul>
                  </div>
                </div>
              </form>
            </section>

          </div>
          <div class="6u 12u(mobile)">

            <!-- Contact -->
            <section class="feature-list small">
              <div class="row">
                <div class="6u 12u(mobile)">
                  <section>
                    <h3 class="icon fa-home">Mailing Address</h3>
                    <p>
                    Untitled Corporation<br />
                    1234 Somewhere Rd #987<br />
                    Nashville, TN 00000-0000
                    </p>
                  </section>
                </div>
                <div class="6u 12u(mobile)">
                  <section>
                    <h3 class="icon fa-comment">Social</h3>
                    <p>
                    <a href="#">@untitled-corp</a><br />
                    <a href="#">linkedin.com/untitled</a><br />
                    <a href="#">facebook.com/untitled</a>
                    </p>
                  </section>
                </div>
              </div>
              <div class="row">
                <div class="6u 12u(mobile)">
                  <section>
                    <h3 class="icon fa-envelope">Email</h3>
                    <p>
                    <a href="#">info@untitled.tld</a>
                    </p>
                  </section>
                </div>
                <div class="6u 12u(mobile)">
                  <section>
                    <h3 class="icon fa-phone">Phone</h3>
                    <p>
                    (000) 555-0000
                    </p>
                  </section>
                </div>
              </div>
            </section>

          </div>
        </div>
        <hr />
      </div>
      <div id="copyright">
        <ul>
          <li>&copy; Untitled</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
        </ul>
      </div>
    </div>
    </div>

    <!-- Scripts -->

    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.dropotron.min.js"></script>
    <script src="assets/js/skel.min.js"></script>
    <script src="assets/js/skel-viewport.min.js"></script>
    <script src="assets/js/util.js"></script>
    <!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
    <script src="assets/js/main.js"></script>
	 <script src="dist/js/lightbox.js"></script>
  </body>
</html>
