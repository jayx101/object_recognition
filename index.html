<!DOCTYPE HTML>
<!--
  Escape Velocity by HTML5 UP
  html5up.net | @ajlkn
  Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
  <head>
    <title>Object Recognition. A Data Science Project by Jacques Oelofse</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
    <link rel="stylesheet" href="assets/css/main.css" />
    <!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
    <link href="dist/css//lightbox.css" rel="stylesheet">
    <script>
  function resizeIframe(obj) {
    obj.style.height = obj.contentWindow.document.body.scrollHeight + 'px';
  }
</script>
  </head>
  <body class="homepage">
    <div id="page-wrapper">

      <!-- Header -->
      <div id="header-wrapper" class="wrapper">
        <div id="header">

          <!-- Logo -->
          <div id="logo">
            <h1><a href="index.html">Object Recognition</a></h1>
            <p>A Data Science project <br>By Jacques Oelofse</p>
          </div>
        </div>
      </div>

      <!-- Intro -->
      <div id="intro-wrapper" class="wrapper style1">
        <div class="title">The Introduction</div>
        <section id="intro" class="container">
          <p class="style1">So in case you were wondering what this is all about ...</p>
          <p class="style2">
          Machine Learning &amp; Computer Vision <br class="mobile-hide" />
          in Manufacturing<br class="mobile-hide" />
          <p class="style3">Computer vision and MES (Manufacturing Execution Systems) have been around for some time. <strong>They are very costly to 
            install and maintain, and complicated to configure.</strong> For this reason, most factories in China still use<strong> spreadsheets.</strong></p>
          <br>
          <p class="style3">In this project I want to create <strong>cost effective and very easy to deploy and maintain</strong> software to track production line metrics
          for the vast amount of suppliers and sub suppliers needed to successfully build a product. The aim is not be 100% accurate but rather to give people complete  
          visibility into their manufacturing in China. <strong>Think Fitbit for manufacturing.</strong>
          </p>
          <br> 
          <p class="style3">This project will demonstrate how we use data from images to build a model and predict products on a production line.</p>
          <br>
          <p class="style1">The goal is to have the ability to quickly train a new product and predict it with at least a 90% accuracy.</p>
          <br>
          <div style="width:70%;height:100%;margin:0 auto;">
          <div class='myIframe'> 
          <iframe
            src="https://www.youtube.com/embed/SFc2fO-x3QM"
            allowfullscren="allowfullscreen" mozallowfullscreen="mozallowfullscreen" msallowfullscreen="msallowfullscreen" oallowfullscreen="oallowfullscreen" webkitallowfullscreen="webkitallowfullscreen">
          </iframe>
          </div>
          </div>
        </section>
      </div>

      <!-- Data -->
      <div class="wrapper style2">
        <div class="title">The Data</div>
        <div id="main" class="container">

          <!-- Features -->
          <section id="features">
            <header class="style1">
              <h2>Data consists of images taken overhead from a Logitech C525 webcam</h2>
            </header>
            <!--Image -->
            <a href="#" class="image featured">
              <img src="images/collage_prod2.jpg" alt="" />
            </a>

            <header style="margin-bottom:1em;padding-bottom:0.5em;" class="style1">
              <p style="margin:0em; margin-bottom:2em; line-height:0em;">Important considerations when working with images</p>
            </header>
            <h3>Computers don't see images like humans do</h3>
            <p>Computers see images with number representations for each pixel (see figl below) If an image has 6x9 pixels (height x width), the computer would see 6x9 = 54 
            number values.</p>
            <h3>Color</h3>
            <p>When an image has color, you are adding 3 additional dimensions. The image will now have three number values for
            each pixel. One for red, one for green and one for blue (RGB). The combination of these values make up your color spectrum (fig2).
            The computer will see the colored image as (6x9)x3 = 162.
            <header style="margin-bottom:1em;padding-bottom:0.5em; margin-top:0; padding-top:0;" class="style1">
              <table>
                <tr>
                  <td>
                    <img class="image fit" style="max-width:400px" src="images/image_array.png" alt="" />
                  </td>
                  <td>
                    <img class="image fit" style="max-width:400px" src="images/rgb.gif" alt="" />
                  </td>
                  <tr>
                    <td>fig1</td>
                    <td>fig2</td>
                  </tr>
              </table>
            </header>
            <h3>Size</h3>
            <p>Important when deciding what level of detail you want to extract from the image, and is usually one of the 
            biggest contributing factors on performance.</p>
            <h3>Angle, Rotation, Scale</h3>
            <p>
            Because computers do not interpret images the same way humans do, they do not automatically understand differences 
            in angle scale and rotation e.g., if you were to look at an person from the front or side, you inherently know its the same person, 
            a computer however will not know the difference unless you specifically program it to.
            </p>
            <h3>Image Segmentation</h3>
            <p>
            This is an area in Computer Vision where you remove an object from the background with a mask.
            For this project we implemented image segmentation to be able to still predict objects when there is noise but we do not
            have allot of test data.
            </p>
            <center>
              <img class="image fit" style="max-width:600px;" src="images/segmentation.png" alt="" />
            </center>
          </section>
        </div>
      </div>

      <!-- Features -->
      <div class="wrapper style3">
        <div class="title">Image Descriptors</div>
        <div id="main" class="container">
        <section id="features">
          <header class="style1">
            <h2>Given two images, how can we determine their similarity?</h2>
            <p>Given two images, how can we determine their similarity? We can measure the pixel to pixel similarity by measuring their Euclidean distance, but that measure is very sensitive to noise, rotation, translation and illumination changes. In most applications we would like to be robust to such change.</p>
            <p>To allow for rotation and scale invariance, we have selected the SURF algorithm to extract the image features. I will give a brief overview of how HOG algorithms works</p>
          </header>
          <h3>1. Detect keypoints</h3>
          <p>
          The most distinctive points on an image are its corners and edges. Think of a jigsaw puzzle. It is easier to together pieces with edges of buildings than pieces of blank sky.
          Similarly the algorithm will use edges an corners as interest points.The Laplacian of the Gaussian is used to detect keypoints. Log acts as a blob detector which 
          can detect blobs in various sizes. An orientation is calculated for each key point. Any further calculations are done relative to this orientation. This effectively cancels out the effect of orientation, making it rotation invariant.
          </p>

          <div class="jrow">
            <div class="jcontainer">
              <img class="jleft" src="images/16x16.jpg" width="50%" />
              <h3>2. Build image descriptors around keypoints</h3>
              <p>
              A 16x16 pixel area or descriptor is built around the center of each interest point.
              </p>
                <div style="clear: both"></div>      
            </div>
          </div>

          </br>

          <div class="jrow">
            <div class="jcontainer">
            <img class="jleft" src="images/gradients.jpg" width="50%" />

            <h3>3. Compute gradients</h3>
            <p>The 16x16 pixels are divided into 4x4 squares and the pixel gradients are calculated. The shows the direction in which the pixels are getting darker.
            </p>
                <div style="clear: both"></div>      
            </div>
          </div>

          </br>

          <div class="jrow">
            <div class="jcontainer">
            <img class="jleft" src="images/hog.jpg" width="50%" height="156" />
            <h3>4. Compute gradient direction histogram</h3>
            <p>
            For each square, compute gradient direction histogram over the 8 directions
            </p>
            <div style="clear: both"></div>      
            </div>
          </div>

          </br>

          <div class="jrow">
            <div class="jcontainer">
              <img class="jleft" src="images/128hist.jpg" width="50%" />

              <h3>5. Concatenate histograms</h3>
              <p>Concatenate the histograms to obtain a 128 (16*8) dimensional feature vector</p>
              <div style="clear: both"></div>      

            </div>
          </div>

          </br>

          <h3>Rotation invariance</h3>
            <p>This shows the algorithms ability to handle rotation</p>
            <center>
          <img class="image fit" style="max-width:800px" src="images/rotation.png" alt="" />
            </center> 
            </br>
            </br>
            <h3>We now have 128 byte vectors for each keypoints found on our image. You can use these descriptors to match keypoints, however we will be using them 
              with a visual bag of words which we will explore further in the next section.<h3>
        </section>
        </div>
      </div>

      <!-- BOW -->
      <div id="footer-wrapper" class="wrapper">
        <div class="title">Visual Bag Of Words</div>
        <div id="footer" class="container">
        <section id="features">

          <header class="style1">
            <p>Bag of words models are a popular technique for image classification inspired by models used in natural language processing. The model ignores or downplays word arrangement (spatial information in the image) and classifies based on a histogram of the frequency of visual words.</p>
          </header>
          <br />
          <br />
          <h3>Why have a vocabulary?</h3>
          <p>
          Images don't have words so we will have to create our own vocabulary. Once we have a vocabulary that describes all the interest points in our images, we can 
          then check how many words each image contains. We can then use the amount of times the words appear to classify the image. If an image had the words eyes, mouth and nose for example, we would classify it as face.
          </p>

          <h3>1. Build a vocabulary of words</h3>
          <p>
          By using the KNN clustering algorithm on the feature descriptors of all of our images. We can group the descriptors into k 
          mutually exclusive clusters. Each cluster center represents a feature, or visual word. All the words will make up the vocabulary.
          <center><img class="image fit" style="max-width:576px;" src="images/visualwordsoverview.png" alt="" /></center>
          </p>

          <h3>2. Create Feature Histogram for Images</h3>
          <p>To create the frequency histogram for each image that, we get the descriptors for all each of our images
          and get get their nearest neighbors to the vocabulary we had created. The amount of times the words match the vocabulary will make up our frequency histogram.</p>
          <center><img class="image fit" style="max-width:612px;" src="images/bagoffeatures.png" alt="" /></center>

          </br>

          <h3>Example</h3>
          <p>
          Images show a basic example of visual BOW. The first image shows our image set. The second image shows what the bag of words might look like 
          after we have clustered the descriptors. The final image shows what a frequency histogram representation of each image might look like.
          <center><img class="image fit" style="max-width:770px;" src="images/bow1.png" alt="" /></center>
          <center><img class="image fit" style="max-width:770px;" src="images/bow2.png" alt="" /></center>
          <center><img class="image fit" style="max-width:770px;" src="images/bow3.png" alt="" /></center>
          </p>
        </div>
        </section>
      </div>
    </div>


    <!-- Classififaction -->
    <div class="wrapper style2">
      <div class="title">Classification</div>
      <div id="main" class="container">
        <!-- Features -->
        <section id="features">
          <header class="style1">
            <h2>Using the feature histograms from our BOW's we will now train a few models and evaluate their performance.</h2>
            <p>
            <center>
          <img class="image fit" style="max-width:648px" src="images/collage_long.png" alt="" />
          </center>
          </p>
          </header>
          <h3>Train and Test Data</h3>
          <p>
          We have 10 different classes in total to classify.  
          For each class we have created roughly 100 images with a total of 1056 images.
          When evaluating the model<strong> we use a test train split of 20% and 80% respectively.</strong>
          </p>
          <h3>Performance with little data</h3>
          <p>SVM and Logistic Regression performed particularly well with very little training data. With a model trained with only two images per class, they 
					get roughly 60% precision and recall however the results can vary significantly when re-training which can be expected because of the small training set.</p>
						<table class="default">
							<thead>
								<tr>
									<th>Model</th>
									<th>Precision</th>
									<th>Recall</th>
									<th>F1-score</th>
									<th>Support</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>Support Vector</td>
									<td>0.70</td>
									<td>0.70</td>
									<td>0.71</td>
									<td>10</td>
								</tr>
								<tr>
									<td>Logistic</td>
									<td>0.63</td>
									<td>0.70</td>
									<td>0.63</td>
									<td>10</td>
								</tr>
								<tr>
									<td>Support Vector RBF</td>
									<td>0.53</td>
									<td>0.50</td>
									<td>0.49</td>
									<td>10</td>
								</tr>
								<tr>
									<td>Random Forest</td>
									<td>0.40</td>
									<td>0.40</td>
									<td>0.37</td>
									<td>10</td>
								</tr>
								<tr>
									<td>Decision Tree</td>
									<td>0.30</td>
									<td>0.30</td>
									<td>0.27</td>
									<td>10</td>
								</tr>
								<tr>
									<td>K Nearest Neigbors</td>
									<td>0.27</td>
									<td>0.40</td>
									<td>0.31</td>
									<td>10</td>
								</tr>
							</tbody>
						</table>

          <h3>Classify 5 Classes</h3>
					<p>With 5 classes with a hundred training images each, the model performs very well at around 97% precision and recall.</p>
						<table class="default">
							<thead>
								<tr>
									<th>Model</th>
									<th>Precision</th>
									<th>Recall</th>
									<th>F1-score</th>
									<th>Support</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>Support Vector</td>
									<td>0.97</td>
									<td>0.97</td>
									<td>0.97</td>
									<td>103</td>
								</tr>
								<tr>
									<td>Logistic</td>
									<td>0.97</td>
									<td>0.97</td>
									<td>0.97</td>
									<td>103</td>
								</tr>
								<tr>
									<td>Support Vector RBF</td>
									<td>0.95</td>
									<td>0.94</td>
									<td>0.94</td>
									<td>103</td>
								</tr>
								<tr>
									<td>Random Forest</td>
									<td>0.91</td>
									<td>0.90</td>
									<td>0.90</td>
									<td>103</td>
								</tr>
								<tr>
									<td>Decision Tree</td>
									<td>0.86</td>
									<td>0.83</td>
									<td>0.84</td>
									<td>103</td>
								</tr>
								<tr>
									<td>K Nearest Neighbors</td>
									<td>0.85</td>
									<td>0.70</td>
									<td>0.70</td>
									<td>103</td>
								</tr>
							</tbody>
						</table>

          <h3>Classify 10 Classes</h3>
          <p>Classifying 10 different product double what we did last, the result is excellent with an increase in performance. The 10 class image set was taken at a higher resolution, however the images have been re-sized to the same size as the 5 class image set.
          The different images may account for the slight increase in performance.</p>
          <table class="default">
							<thead>
								<tr>
									<th>Model</th>
									<th>Precision</th>
									<th>Recall</th>
									<th>F1-score</th>
									<th>Support</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>Support Vector</td>
									<td>0.99</td>
									<td>0.99</td>
									<td>0.99</td>
									<td>212</td>
								</tr>
								<tr>
									<td>Logistic</td>
									<td>0.94</td>
									<td>0.92</td>
									<td>0.92</td>
									<td>212</td>
								</tr>
								<tr>
									<td>Support Vector RBF</td>
									<td>0.99</td>
									<td>0.99</td>
									<td>0.99</td>
									<td>212</td>
								</tr>
								<tr>
									<td>Random Forest</td>
									<td>0.96</td>
									<td>0.96</td>
									<td>0.96</td>
									<td>212</td>
								</tr>
								<tr>
									<td>Decision Tree</td>
									<td>0.85</td>
									<td>0.84</td>
									<td>0.84</td>
									<td>212</td>
								</tr>
								<tr>
									<td>K Nearest Neighbors</td>
									<td>0.97</td>
									<td>0.96</td>
								</tr>

							</tbody>
						</table>

          <h3>Image Size on Performance</h3>
          <p>Here we wanted to look at what impact image size would have on the models performance. With every increase of about 100px width (width and height changed proportionally), the performance went up roughly 2%
          </br> 
          click to zoom </br>
					<a href="images/image_scores.png" data-lightbox="image-1" data-title="Image Size Scores"><img width="100" style="" src="images/image_scores.png" alt="" /></a>
          </p>
          <h3>BOW Size</h3>
          <center><img class="image fit" style="" src="images/feature_importance.png" alt="" /></center>
          <p>
          BOW size will impact how many words KNN clusters which will be the size of you feature dimension. The more words you have, the more detail can be extracted from each image.
          To decide the ideal size for the BOW we looked at feature importances from the Random Forest model. This is show as "gini importance" or "mean decrease impurity" and is defined as the total decrease in node impurity as percentage ranked by importance

           </br> 
          click to zoom </br>
					<a href="images/bow_scores.png" data-lightbox="image-1" data-title="BOW Scores"><img width="100" style="" src="images/bow_scores.png" alt="" /></a>
          </p>

          <h3>Noise</h3>
          <p>
          All the training images were trained on clear backgrounds, this is similar to the actual manufacturing environment. For this problem we also want to be able to quickly 
          classify new products as they are added to the manufacturing line. This would mean you would start with a small training set and build up to a larger set that will be 
          able to handle noise more effectively. In the video, you will see we have added some noise to the image. The classification performs as expected and miss-classifies the product.
          Using image Segmentation to reduce the noise, we overcome the problem.
          </p>

          <center>
          <div style="width:70%;height:100%;margin:0 auto;"">
          <div class='myIframe'> 
            <iframe
              src="https://www.youtube.com/embed/nS-eiTUkc7Y"
              </
              allowfullscreen="allowfullscreen" mozallowfullscreen="mozallowfullscreen" msallowfullscreen="msallowfullscreen" oallowfullscreen="oallowfullscreen" webkitallowfullscreen="webkitallowfullscreen"
              >
            </iframe>
            </div>
            </div>
          </center>

          </br>

          <h3>Summary</h3>
          SVM was our best performing classifier. 
          We found that creating the BOW, and training the model was computationally heavy and for the thousand images could take a few minutes. For the manufacturing use case, 
          this can potentially pose a problem as we want to be continually training our model as we get new images. Having the BOW at 600 words, and the image size at 300px gives a good
          balance of training speed and prediction accuracy.
          I performed a grid search on various C and intercept parameters with no improvements.

        </section>
      </div>
    </div>

    <!-- Conclusion -->
    <div class="wrapper style3">
      <div class="title">Finally</div>
      <div id="highlights" class="container">
        <header class="style1">
          <h2>Conclusion</h2>
          <p>Overall, the SURF descriptors, visual bag of words and image segmentation provide a great combination for predicting products with a limited amount of training data.
          For the 10 products, we tested the accuracy was exceptional. I believe this to be a viable solution for manufacturing production line tracking.</p>
        </header>
        <header class="style1">
          <h2>Next Steps</h2>
          <p>Add the ability to predict that a newly introduced product does not belong to any of the classes. We can do this by adding a negative training set. Ten classes are not enough for the products intended purpose, so adding another 20 classes.
          Finally getting actual manufacturing backgrounds and ascertaining how the model performs with the noise, and how many images per class will be needed for the model to perform well.</p>
        </header>
      </div>
    </div>

    <!-- Footer -->
    <div id="footer-wrapper" class="wrapper">
      <div class="title">the rest of it</div>
      <div id="footer" class="container">
        <header class="style1">
        </header>
        <hr />
        <div class="row 150%">
          <div class="6u 12u(mobile)">

            <!-- contact form -->
            <section>
              <form method="post" action="#">
                <div class="row 50%">
                  <div class="6u 12u(mobile)">
                    <input type="text" name="name" id="contact-name" placeholder="name" />
                  </div>
                  <div class="6u 12u(mobile)">
                    <input type="text" name="email" id="contact-email" placeholder="email" />
                  </div>
                </div>
                <div class="row 50%">
                  <div class="12u">
                    <textarea name="message" id="contact-message" placeholder="message" rows="4"></textarea>
                  </div>
                </div>
                <div class="row">
                  <div class="12u">
                    <ul class="actions">
                      <li><input type="submit" class="style1" value="send" /></li>
                      <li><input type="reset" class="style2" value="reset" /></li>
                    </ul>
                  </div>
                </div>
              </form>
            </section>

          </div>
          <div class="6u 12u(mobile)">

            <!-- contact -->
            <section class="feature-list small">
              <div class="row">
<!--                 <div class="6u 12u(mobile)">
                  <section>
                    <h3 class="icon fa-home">mailing address</h3>
                    <p>
                    untitled corporation<br />
                    1234 somewhere rd #987<br />
                    nashville, tn 00000-0000
                    </p>
                  </section>
                </div> -->
                <div class="6u 12u(mobile)">
                  <section>
                    <h3 class="icon fa-comment">social</h3>
                    <p>
                    <a href="www.linkedin.com/in/jacquesoelofse
">LinkedIn</a><br />
                    <!-- <a href="#">facebook.com/untitled</a> -->
                    </p>
                  </section>
                </div>
              </div>
              <div class="row">
                <div class="6u 12u(mobile)">
                  <section>
                    <h3 class="icon fa-envelope">email</h3>
                    <p>
                    <a href="mailto:oelofsej@gmail.com">oelofsej@gmail.com</a>
                    </p>
                  </section>
                </div>
                <div class="6u 12u(mobile)">
                  <section>
                    <h3 class="icon fa-phone">phone</h3>
                    <p>
                    (000) 555-0000
                    </p>
                  </section>
                </div>
              </div>
            </section>

          </div>
        </div>
        <hr />
      </div>
      <div id="copyright">
        <ul>
          <li>&copy; untitled</li><li>design: <a href="http://html5up.net">html5 up</a></li>
        </ul>
      </div>
    </div>
    </div>

    <!-- Scripts -->

    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.dropotron.min.js"></script>
    <script src="assets/js/skel.min.js"></script>
    <script src="assets/js/skel-viewport.min.js"></script>
    <script src="assets/js/util.js"></script>
    <!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
    <script src="assets/js/main.js"></script>
	 <script src="dist/js/lightbox.js"></script>
  </body>
</html>
